{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>Review</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dev_pid_1</td>\n",
       "      <td>I enjoyed today, and I still am! Tomorrows dep...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dev_pid_2</td>\n",
       "      <td>I sorta tried to kill myself : I had a total b...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dev_pid_3</td>\n",
       "      <td>Best suicide method? : I like it quick and eas...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dev_pid_4</td>\n",
       "      <td>a story : I remember the time I'd get on my 3D...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dev_pid_5</td>\n",
       "      <td>The world only cares about beautiful people : ...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         PID                                             Review     Label\n",
       "0  dev_pid_1  I enjoyed today, and I still am! Tomorrows dep...  moderate\n",
       "1  dev_pid_2  I sorta tried to kill myself : I had a total b...  moderate\n",
       "2  dev_pid_3  Best suicide method? : I like it quick and eas...  moderate\n",
       "3  dev_pid_4  a story : I remember the time I'd get on my 3D...  moderate\n",
       "4  dev_pid_5  The world only cares about beautiful people : ...  moderate"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/home/redleaf/Documents/DUK/NLP/NLP_PROJECT_DEPRESSION/Augdata.csv\")\n",
    "df = df.rename(columns={'data':'Review'}, inplace=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5576"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "stop_words = nlp.Defaults.stop_words\n",
    "punctuations = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_tokenizer(sentence):\n",
    "    # Creating our token object, which is used to create documents with linguistic annotations.\n",
    "    doc = nlp(sentence)\n",
    "\n",
    "    # Lemmatizing each token and converting each token into lowercase\n",
    "    mytokens = [word.lemma_.lower().strip() for word in doc]\n",
    "\n",
    "    # Removing stop words and punctuations\n",
    "    mytokens = [word for word in mytokens if word not in stop_words and word not in punctuations]\n",
    "\n",
    "    # Return preprocessed list of tokens\n",
    "    return mytokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review'] = df['Review'].apply(spacy_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>Review</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dev_pid_1</td>\n",
       "      <td>[enjoy, today, tomorrow, depression, wait, tod...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dev_pid_2</td>\n",
       "      <td>[sorta, try, kill, total, breakdown, fucking, ...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dev_pid_3</td>\n",
       "      <td>[good, suicide, method, like, quick, easy, def...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dev_pid_4</td>\n",
       "      <td>[story, remember, time, 3ds, play, nintendogs,...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dev_pid_5</td>\n",
       "      <td>[world, care, beautiful, people, bear, ugly, u...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         PID                                             Review     Label\n",
       "0  dev_pid_1  [enjoy, today, tomorrow, depression, wait, tod...  moderate\n",
       "1  dev_pid_2  [sorta, try, kill, total, breakdown, fucking, ...  moderate\n",
       "2  dev_pid_3  [good, suicide, method, like, quick, easy, def...  moderate\n",
       "3  dev_pid_4  [story, remember, time, 3ds, play, nintendogs,...  moderate\n",
       "4  dev_pid_5  [world, care, beautiful, people, bear, ugly, u...  moderate"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Review = [\" \".join(doc) for doc in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.Review\n",
    "Y = df.Label\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.8, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       enjoy today tomorrow depression wait today war...\n",
      "1       sorta try kill total breakdown fucking car par...\n",
      "2       good suicide method like quick easy deformity ...\n",
      "3       story remember time 3ds play nintendogs grandp...\n",
      "4       world care beautiful people bear ugly ugly lif...\n",
      "                              ...                        \n",
      "5571    aren t tired ve frankly_barmy month lose trust...\n",
      "5572    need help cope life pretty figure select good ...\n",
      "5573    qutte zoloft cold turkey wasthe aalborg_kasper...\n",
      "5574    cry m dominic_rhodes_plow antidepressant icoul...\n",
      "5575    seek advice overcome deal problem rant 30 year...\n",
      "Name: Review, Length: 5576, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enjoy today tomorrow depression wait today warm cozy :) tea complement sandwich crazy time live beginning world shamble feel werid stranger come save course debt repay grateful debt crazy dollar change situation day ability relax clean warm tomorrow reality motel ourself panic past week 3 day exspecially bless week sure week till payday pull loan leave planet fitness okay actually gas wise idk find safe place park extended period time werid surprise stand panic stay home night kinda like motel 500 buck week maybe scrap car room know remember saving 500 like big deal wrong 500 sneeze like june seriously consider scrape car guarantee place stay save 2 3 month ... idk today actually sad guess time like week analyze situation rational thought tomorrow hunt maybe find random gig like pay loan early easy work eat march 27th hurry\n"
     ]
    }
   ],
   "source": [
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enjoy today tomorrow depression wait today warm cozy :) tea complement sandwich crazy time live beginning world shamble feel werid stranger come save course debt repay grateful debt crazy dollar change situation day ability relax clean warm tomorrow reality motel ourself panic past week 3 day exspecially bless week sure week till payday pull loan leave planet fitness okay actually gas wise idk find safe place park extended period time werid surprise stand panic stay home night kinda like motel 500 buck week maybe scrap car room know remember saving 500 like big deal wrong 500 sneeze like june seriously consider scrape car guarantee place stay save 2 3 month ... idk today actually sad guess time like week analyze situation rational thought tomorrow hunt maybe find random gig like pay loan early easy work eat march 27th hurry\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X))\n",
    "print(type(X_train))\n",
    "print(type(X_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "model_pipeline_svm = Pipeline([('tfidf',TfidfVectorizer()), ('svm',SVC())])\n",
    "\n",
    "#trian the model\n",
    "model_pipeline_svm.fit(X_train, Y_train)\n",
    "\n",
    "#Predict on the test set\n",
    "y_pred_svm = model_pipeline_svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics for SVM Model\n",
      "--------------------------------\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      moderate       0.66      0.78      0.71       460\n",
      "not depression       0.66      0.55      0.60       358\n",
      "        severe       0.98      0.88      0.93       298\n",
      "\n",
      "      accuracy                           0.73      1116\n",
      "     macro avg       0.76      0.74      0.75      1116\n",
      "  weighted avg       0.74      0.73      0.73      1116\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "classification_report_svm = classification_report(Y_test,y_pred_svm)\n",
    "\n",
    "print(\"Evaluation Metrics for SVM Model\")\n",
    "print(\"--------------------------------\")\n",
    "print(classification_report_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['depression-classification.pkl']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "dump(model_pipeline_svm,'depression-classification.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
